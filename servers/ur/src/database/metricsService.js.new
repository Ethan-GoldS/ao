/**
 * PostgreSQL-based metrics service
 * Handles storage and retrieval of request metrics data
 */
import { query } from './db.js'
import { logger } from '../logger.js'

const _logger = logger.child('metricsService')

/**
 * Store request metrics in the database
 * @param {Object} details Request details object
 * @returns {Promise<boolean>} Success status
 */
export async function storeMetrics(details) {
  try {
    if (!details || !details.processId) {
      _logger('Invalid request details for metrics storage')
      return false
    }

    const {
      processId,
      ip,
      referer,
      method,
      path,
      userAgent,
      origin,
      contentType,
      requestBody,
      rawBody,
      responseBody,
      action,
      duration,
      timeReceived,
      timeCompleted
    } = details

    // Parse JSON body if it's a string
    let parsedBody = requestBody
    if (typeof requestBody === 'string') {
      try {
        parsedBody = JSON.parse(requestBody)
      } catch (e) {
        _logger('Failed to parse request body as JSON: %s', e.message)
        parsedBody = { rawBody: requestBody }
      }
    }

    // Here we're making sure raw body is a string and properly formatted for DB storage
    let rawBodyForStorage = null;
    if (rawBody) {
      if (typeof rawBody === 'string') {
        rawBodyForStorage = rawBody;
      } else {
        try {
          rawBodyForStorage = JSON.stringify(rawBody);
        } catch (e) {
          _logger('Failed to stringify raw body: %s', e.message);
          // Use string representation as fallback
          rawBodyForStorage = String(rawBody);
        }
      }
    }

    // Store response body too if available
    let responseBodyForStorage = null;
    if (responseBody) {
      if (typeof responseBody === 'string') {
        responseBodyForStorage = responseBody;
      } else {
        try {
          responseBodyForStorage = JSON.stringify(responseBody);
        } catch (e) {
          _logger('Failed to stringify response body: %s', e.message);
          responseBodyForStorage = String(responseBody);
        }
      }
    }

    // Check if table has request_raw column before inserting
    const result = await query(
      `INSERT INTO metrics_requests (
        process_id, request_ip, request_referrer, request_method, 
        request_path, request_user_agent, request_origin, request_content_type,
        request_body, request_raw, response_body, action, duration, time_received, time_completed
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
      RETURNING id`,
      [
        processId,
        ip || 'unknown',
        referer || 'unknown',
        method || 'unknown',
        path || 'unknown',
        userAgent || 'unknown',
        origin || 'unknown',
        contentType || 'unknown',
        parsedBody ? JSON.stringify(parsedBody) : null,
        rawBodyForStorage,
        responseBodyForStorage,
        action || 'unknown',
        duration || 0,
        timeReceived ? new Date(timeReceived) : new Date(),
        timeCompleted ? new Date(timeCompleted) : new Date()
      ]
    )

    const id = result.rows[0]?.id
    _logger('Successfully stored metrics for process %s with ID %d', processId, id)

    // Verify the data was actually inserted
    try {
      const verifyResult = await query('SELECT * FROM metrics_requests WHERE id = $1', [id])
      if (verifyResult.rows.length > 0) {
        const row = verifyResult.rows[0]
        _logger('Verified stored metrics - process_id: %s, time_received: %s', 
          row.process_id, row.time_received)
      } else {
        _logger('WARNING: Could not verify stored metrics with ID %d - record not found', id)
      }
    } catch (verifyErr) {
      _logger('WARNING: Error verifying stored metrics: %O', verifyErr)
    }

    return true
  } catch (error) {
    _logger('ERROR: Failed to store metrics: %O', error)
    return false
  }
}

/**
 * Get recent request metrics
 * @param {Number} limit Maximum number of requests to return
 * @returns {Promise<Array>} Recent requests
 */
export async function getRecentRequests(limit = 100) {
  try {
    const result = await query(
      `SELECT * FROM metrics_requests
       ORDER BY time_received DESC
       LIMIT $1`,
      [limit]
    );
    
    return result.rows.map(row => ({
      id: row.id,
      process_id: row.process_id,
      processId: row.process_id, // Include both formats for compatibility
      request_ip: row.request_ip,
      ip: row.request_ip, // Include both formats for compatibility
      request_referrer: row.request_referrer,
      referer: row.request_referrer,
      request_method: row.request_method,
      method: row.request_method,
      request_path: row.request_path,
      path: row.request_path,
      request_user_agent: row.request_user_agent,
      userAgent: row.request_user_agent,
      request_origin: row.request_origin,
      origin: row.request_origin,
      request_content_type: row.request_content_type,
      contentType: row.request_content_type,
      request_body: row.request_body,
      requestBody: row.request_body,
      request_raw: row.request_raw,
      rawBody: row.request_raw, // Include both formats for compatibility
      action: row.action,
      duration: row.duration,
      timestamp: row.time_received || row.timestamp, // Use time_received if available, timestamp as fallback
      time_received: row.time_received,
      timeReceived: row.time_received,
      time_completed: row.time_completed,
      timeCompleted: row.time_completed
    }))
  } catch (error) {
    _logger('Error getting recent requests: %O', error)
    return []
  }
}

/**
 * Get process metrics aggregated by process ID
 * @returns {Promise<Object>} Process metrics
 */
export async function getProcessMetrics() {
  try {
    const countResult = await query(
      `SELECT 
         process_id,
         COUNT(*) as request_count,
         AVG(duration) as avg_duration,
         MAX(time_received) as last_request
       FROM metrics_requests
       GROUP BY process_id
       ORDER BY request_count DESC`
    )

    return countResult.rows.map(row => ({
      processId: row.process_id,
      requestCount: parseInt(row.request_count, 10),
      avgDuration: parseFloat(row.avg_duration) || 0,
      lastRequest: row.last_request ? row.last_request.toISOString() : null
    }))
  } catch (error) {
    _logger('Error getting process metrics: %O', error)
    return []
  }
}

/**
 * Get action metrics aggregated by action
 * @returns {Promise<Object>} Action metrics
 */
export async function getActionMetrics() {
  try {
    const actionResult = await query(
      `SELECT 
         action,
         COUNT(*) as request_count,
         AVG(duration) as avg_duration,
         MAX(time_received) as last_request
       FROM metrics_requests
       GROUP BY action
       ORDER BY request_count DESC`
    )

    return actionResult.rows.map(row => ({
      action: row.action,
      requestCount: parseInt(row.request_count, 10),
      avgDuration: parseFloat(row.avg_duration) || 0,
      lastRequest: row.last_request ? row.last_request.toISOString() : null
    }))
  } catch (error) {
    _logger('Error getting action metrics: %O', error)
    return []
  }
}

/**
 * Get client metrics (IP and referrer counts)
 * @returns {Promise<Object>} Client metrics
 */
export async function getClientMetrics() {
  try {
    // Get IP address counts
    const ipResult = await query(
      `SELECT 
         request_ip as ip,
         COUNT(*) as request_count
       FROM metrics_requests
       GROUP BY request_ip
       ORDER BY request_count DESC
       LIMIT 10`
    )

    // Get referrer counts
    const referrerResult = await query(
      `SELECT 
         request_referrer as referrer,
         COUNT(*) as request_count
       FROM metrics_requests
       GROUP BY request_referrer
       ORDER BY request_count DESC
       LIMIT 10`
    )

    const ipAddresses = ipResult.rows.map(row => ({
      ip: row.ip,
      requestCount: parseInt(row.request_count, 10)
    }))

    const referers = referrerResult.rows.map(row => ({
      referrer: row.referrer,
      requestCount: parseInt(row.request_count, 10)
    }))

    return {
      ipAddresses,
      referers
    }
  } catch (error) {
    _logger('Error getting client metrics: %O', error)
    return {
      ipAddresses: [],
      referers: []
    }
  }
}

/**
 * Format date for time bucket display
 * @param {Date} date Date to format
 * @param {String} interval Interval type
 * @returns {String} Formatted date string
 */
function formatDateForBucket(date, interval) {
  if (interval === 'minute') {
    return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
  } else if (interval === '5min' || interval === '10min' || interval === '15min' || interval === '30min') {
    return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
  } else if (interval === 'hour') {
    return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
  } else if (interval === 'day') {
    return date.toLocaleDateString([], { month: 'short', day: 'numeric' });
  }
  
  // Default format
  return date.toLocaleString([], { month: 'short', day: 'numeric', hour: '2-digit', minute: '2-digit' });
}

/**
 * Get time series data for requests over time
 * @param {Number} hours Number of hours to include in time series
 * @param {String} interval Interval for data grouping ('minute', '5min', '10min', '15min', '30min', 'hour', 'day')
 * @param {Date} startDate Optional start date for custom time ranges
 * @param {Date} endDate Optional end date for custom time ranges
 * @param {Array} processIds Optional array of process IDs to filter by
 * @returns {Promise<Object>} Time series data
 */
export async function getTimeSeriesData(hours = 24, interval = 'hour', startDate = null, endDate = null, processIds = null) {
  try {
    // Convert interval to PostgreSQL interval string
    let pgInterval;
    let truncFunc;
    
    switch(interval) {
      case 'minute': pgInterval = '1 minute'; truncFunc = 'minute'; break;
      case '5min': pgInterval = '5 minutes'; truncFunc = 'hour'; break;
      case '10min': pgInterval = '10 minutes'; truncFunc = 'hour'; break;
      case '15min': pgInterval = '15 minutes'; truncFunc = 'hour'; break;
      case '30min': pgInterval = '30 minutes'; truncFunc = 'hour'; break;
      case 'hour': pgInterval = '1 hour'; truncFunc = 'hour'; break;
      case 'day': pgInterval = '1 day'; truncFunc = 'day'; break;
      default: pgInterval = '1 hour'; truncFunc = 'hour';
    }
    
    _logger('Getting time series data with interval: %s, hours: %d', interval, hours);
    
    // Check table schema and available columns
    const allColumns = await query(
      `SELECT column_name, data_type
       FROM information_schema.columns
       WHERE table_name = 'metrics_requests'
       ORDER BY ordinal_position`
    );
    
    const availableColumns = allColumns.rows.map(row => row.column_name);
    _logger('Available columns: %O', availableColumns);
    
    // Determine which timestamp column to use (time_received or timestamp)
    const timeColumn = availableColumns.includes('time_received') ? 'time_received' : 
                      availableColumns.includes('timestamp') ? 'timestamp' : null;
    
    if (!timeColumn) {
      _logger('ERROR: No timestamp column found in metrics_requests table');
      throw new Error('No timestamp column available in database');
    }
    
    _logger('Using time column: %s', timeColumn);
    
    // Build the time range conditions
    let timeCondition;
    let params = [];
    let paramIndex = 1;
    
    if (startDate && endDate) {
      // Use custom date range
      timeCondition = `${timeColumn} BETWEEN $${paramIndex++} AND $${paramIndex++}`;
      params.push(new Date(startDate));
      params.push(new Date(endDate));
      _logger('Using custom date range: %s to %s', startDate, endDate);
    } else {
      // Use hours-based range
      timeCondition = `${timeColumn} > NOW() - interval '${hours} hours'`;
      _logger('Using last %d hours range', hours);
    }
    
    // Add process ID filtering if requested
    let processCondition = '';
    if (processIds && processIds.length > 0) {
      const placeholders = processIds.map(() => `$${paramIndex++}`).join(',');
      processCondition = ` AND process_id IN (${placeholders})`;
      params = [...params, ...processIds];
      _logger('Filtering by process IDs: %O', processIds);
    }
    
    // Build the query with proper column quoting and escaping
    const query_text = `
      SELECT 
        date_trunc($${paramIndex++}, ${timeColumn}) as time_bucket,
        COUNT(*) as total_requests,
        jsonb_object_agg(process_id, process_count) as process_counts
      FROM (
        SELECT 
          date_trunc($${paramIndex++}, ${timeColumn}) as time_bucket,
          process_id,
          COUNT(*) as process_count
        FROM metrics_requests
        WHERE ${timeCondition}${processCondition}
        GROUP BY time_bucket, process_id
        ORDER BY time_bucket, process_count DESC
      ) AS bucketed_counts
      GROUP BY time_bucket
      ORDER BY time_bucket ASC
    `;
    
    // Add the interval parameters
    params.push(truncFunc, truncFunc);
    
    _logger('Executing time series query with params: %O', params);
    
    try {
      const result = await query(query_text, params, 20000); // 20 second timeout
      return await processTimeSeriesResults(result, hours, interval, startDate, endDate);
    } catch (queryErr) {
      _logger('Error executing time series query: %O', queryErr);
      throw queryErr;
    }
  } catch (error) {
    _logger('Error getting time series data: %O', error);
    // Generate empty time series data
    const timeLabels = [];
    const timeSeriesData = [];
    const now = new Date();
    const startTime = startDate ? new Date(startDate) : new Date(now.getTime() - hours * 60 * 60 * 1000);
    const endTime = endDate ? new Date(endDate) : now;
    
    // Determine interval in milliseconds
    let intervalMs;
    switch(interval) {
      case 'minute': intervalMs = 60 * 1000; break;
      case '5min': intervalMs = 5 * 60 * 1000; break;
      case '10min': intervalMs = 10 * 60 * 1000; break;
      case '15min': intervalMs = 15 * 60 * 1000; break;
      case '30min': intervalMs = 30 * 60 * 1000; break;
      case 'hour': intervalMs = 60 * 60 * 1000; break;
      case 'day': intervalMs = 24 * 60 * 60 * 1000; break;
      default: intervalMs = 60 * 60 * 1000; // Default to hourly
    }
    
    // Generate appropriate number of empty buckets
    const duration = endTime.getTime() - startTime.getTime();
    const numBuckets = Math.ceil(duration / intervalMs);
    
    for (let i = 0; i < numBuckets; i++) {
      const bucketTime = new Date(startTime.getTime() + i * intervalMs);
      timeLabels.push(formatDateForBucket(bucketTime, interval));
      
      timeSeriesData.push({
        timestamp: bucketTime.toISOString(),
        totalRequests: 0,
        processCounts: {}
      });
    }
    
    return { timeSeriesData, timeLabels };
  }
}

/**
 * Process time series results into expected format
 * @param {Object} result Query result
 * @param {Number} hours Number of hours
 * @param {String} interval Interval for data grouping
 * @param {Date} startDate Optional start date for custom time ranges
 * @param {Date} endDate Optional end date for custom time ranges
 * @returns {Promise<Object>} Processed time series data
 */
async function processTimeSeriesResults(result, hours, interval = 'hour', startDate = null, endDate = null) {
  _logger('Processing time series results. Found %d buckets', result.rows.length);
  
  const timeSeriesData = [];
  
  if (result.rows.length > 0) {
    for (const row of result.rows) {
      timeSeriesData.push({
        timestamp: row.time_bucket.toISOString(),
        totalRequests: parseInt(row.total_requests, 10),
        processCounts: row.process_counts || {}
      });
    }
  } else {
    // No data in the results, create empty buckets
    _logger('No time series data found, creating empty buckets');
    const now = new Date();
    const startTime = startDate ? new Date(startDate) : new Date(now.getTime() - hours * 60 * 60 * 1000);
    const endTime = endDate ? new Date(endDate) : now;
    
    // Determine interval in milliseconds
    let intervalMs;
    switch(interval) {
      case 'minute': intervalMs = 60 * 1000; break;
      case '5min': intervalMs = 5 * 60 * 1000; break;
      case '10min': intervalMs = 10 * 60 * 1000; break;
      case '15min': intervalMs = 15 * 60 * 1000; break;
      case '30min': intervalMs = 30 * 60 * 1000; break;
      case 'hour': intervalMs = 60 * 60 * 1000; break;
      case 'day': intervalMs = 24 * 60 * 60 * 1000; break;
      default: intervalMs = 60 * 60 * 1000; // Default to hourly
    }
    
    // Generate appropriate number of empty buckets
    const duration = endTime.getTime() - startTime.getTime();
    const numBuckets = Math.ceil(duration / intervalMs);
    
    for (let i = 0; i < numBuckets; i++) {
      const bucketTime = new Date(startTime.getTime() + i * intervalMs);
      timeSeriesData.push({
        timestamp: bucketTime.toISOString(),
        totalRequests: 0,
        processCounts: {}
      });
    }
  }
  
  // Sort by timestamp ascending (oldest first)
  timeSeriesData.sort((a, b) => 
    new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
  );
  
  // Create time labels for Chart.js based on the interval
  const timeLabels = timeSeriesData.map(d => {
    const date = new Date(d.timestamp);
    return formatDateForBucket(date, interval);
  });
  
  _logger('Processed time series data with %d buckets', timeSeriesData.length);
  
  return { timeSeriesData, timeLabels };
}

/**
 * Get total statistics
 * @returns {Promise<Object>} Total statistics
 */
export async function getTotalStats() {
  try {
    const result = await query(
      `SELECT 
         COUNT(*) as total_requests,
         COUNT(DISTINCT process_id) as unique_processes,
         COUNT(DISTINCT request_ip) as unique_ips,
         MIN(time_received) as start_time,
         AVG(duration) as avg_duration
       FROM metrics_requests`
    );

    const row = result.rows[0];
    return {
      totalRequests: parseInt(row.total_requests, 10),
      uniqueProcesses: parseInt(row.unique_processes, 10),
      uniqueIps: parseInt(row.unique_ips, 10),
      avgDuration: parseFloat(row.avg_duration) || 0,
      startTime: row.start_time ? row.start_time.toISOString() : new Date().toISOString()
    };
  } catch (error) {
    _logger('Error getting total stats: %O', error);
    return {
      totalRequests: 0,
      uniqueProcesses: 0,
      uniqueIps: 0,
      avgDuration: 0,
      startTime: new Date().toISOString()
    };
  }
}

/**
 * Get all metrics for dashboard display
 * @param {Object} options Optional filtering parameters
 * @returns {Promise<Object>} All metrics
 */
export async function getAllMetrics(options = {}) {
  try {
    _logger('Getting all metrics for dashboard with options: %O', options);
    
    const {
      hours = 24,
      interval = 'hour',
      startDate = null,
      endDate = null,
      processIds = null
    } = options;
    
    // Get overall stats
    const stats = await getTotalStats();
    
    // Get recent requests
    const recentRequests = await getRecentRequests(100);
    
    // Get process metrics (sorted by count)
    const processes = await getProcessMetrics();
    
    // Get action metrics (sorted by count)
    const actions = await getActionMetrics();
    
    // Get client metrics (IP and referrer)
    const clients = await getClientMetrics();
    
    // Get time series data with provided options
    const timeData = await getTimeSeriesData(hours, interval, startDate, endDate, processIds);
    
    // Return consolidated metrics object
    return {
      stats,
      recentRequests,
      processes,
      actions,
      clients,
      timeData
    };
  } catch (error) {
    _logger('Error getting all metrics: %O', error);
    
    // Return partial data or empty objects on error
    return {
      stats: { totalRequests: 0, avgDuration: 0 },
      recentRequests: [],
      processes: [],
      actions: [],
      clients: { ipAddresses: [], referers: [] },
      timeData: {
        timeSeriesData: [],
        timeLabels: []
      }
    };
  }
}

/**
 * Helper function to truncate a date to the nearest hour
 * @param {Date} date Date to truncate
 * @returns {Date} Date truncated to hour
 */
function date_trunc_hour(date) {
  const truncated = new Date(date);
  truncated.setMinutes(0, 0, 0);
  return truncated;
}
